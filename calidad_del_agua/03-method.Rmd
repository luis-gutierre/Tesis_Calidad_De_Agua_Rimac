# 3.METODOS {-}

**3.1APLICANDO CLUSTER JERARQUICO** 

***AGRUPAMIENTO DE INDIVIDUOS***




```{r}
library(readxl)
datosc <- read_excel("data_media.xlsx")

```

Estructura:
Tenemos 24 variables de formato numerico  y 1 variable en formato character(meses)
```{r}
str(datosc)
```
Convirtiendo en un dataframe:
```{r}
datosc=as.data.frame(datosc)
```

```{r}
rownames(datosc)<- datosc$meses
```
Eliminanos la variable meses(cualitativa)
```{r}
datosc$meses=NULL
head(datosc,3)
```
**ANALISIS EXPLORATORIO**
```{r}
#Verificando si hay valores faltantes:
#Detectando y graficando los % de datos perdidos
#No hay valores perdidos en ninguna variable
library(DataExplorer)
library(ggplot2)
plot_missing(datosc,ggtheme=theme_minimal())
```
```{r}
#estandarizamos los datos porque las variables se encuentran en diferentes escalas
 datosc <- as.data.frame(scale(datosc))
```

**CLUSTER JERARQUICO AGLOMERATIVO**

Distancia euclidiana  y metodo de enlace Ward.D2

```{r}


#-----------------------------------
#calculando la matriz de disimilaridad




d <- dist(datosc, method = "euclidean")

#el metodo ward.d2 ,para reconstruir la matriz distancia
res.hc <- hclust(d, method = "ward.D2" ) 
```

```{r}
res.hc$merge
#formacion de "n" cluster hasta 1 cluster

#observamos  que son 11 etapas:

#En la etapa 1 
#el individuo 10 y el individuo 11 forman un cluster

#En la entapa 2
#el individuo 8 y el individuo 9 forman un cluster

#y asi sucesivamente hasta llegar a la etapa 11 donde se  
#forma un solo  cluster
```
```{r}
#estructura:
str(res.hc)


options(scipen = 999)#sin notacion cientifica
 
```

```{r}
#distancia 
 res.hc$height
```

**EL NUMERO DE CLUSTER**
```{r}
#Hemos considerado que un cambio brusco seria de la etapa 9
#a la etapa 10,entonces el numero de cluster es 3
library(ggplot2)
alturas <- data.frame(etapa=1:11,distancia=res.hc$height)#distancia 
alturas

```
```{r}
#screeplot con las distancias

ggplot(alturas) + aes(x=etapa,y=distancia)  +
  geom_point() + geom_line()  + 
  scale_x_continuous(breaks=seq(1,15)) + 
  geom_vline(xintercept = 9,col="red",lty=2) + 
  theme_bw() 
```


```{r}
# Dividir en 3 clusters

#La asignacion de cada elemento(mes) a cada cluster

grp <- cutree(res.hc, k = 3)
grp 
#cluster1:
#enero,mayo,octubre,noviembre y diciembre

#cluster2:
#febrero,marzo,abril

#cluster3:
#junio,julio,agosto,setiembre


```

**DEDONGRAMA**

```{r}

#visualizacion de los 3 cluster:

library(factoextra)
fviz_dend(res.hc, k=3, cex = 0.5,
          k_colors = rainbow(3),   # Colores del arco iris
          color_labels_by_k = TRUE, 
          rect=T)

#conclusion del dendograma:

#estiage(fujo bajo del rio):

#junio,julio,agosto y setiembre

#transicion(incremento o disminucion del  flujo del rio):

#octubre, noviembre , diciembre , enero y mayo

#avenida(flujo alto de rio):
 
#febrero, marzo y abril.

#En nuestro dendograma concluimos que los meses de transicion son 
#octubre, noviembre , diciembre , enero y mayo son meses que 
#esta en un ritmo de cambio o bien sube el nivel del agua del rio 
#o bien baja el nivel del agua del rio,es decir 
#para que el nivel del agua del rio sea de flujo alto(avenida),en los
#meses previos como enero,diciembre,noviembre,octubre tuvo que aumentar
#de poco a poco el nivel del agua hasta que febrero,marzo y abril 
#(periodo flujo del rio es alto),luego llegando al mes de mayo 
#comienza a disminuir el nivel del agua de rio rimac este es el mes transicion
#despues en los meses posteriores  junio,julio,agosto y setiembre 
#el nivel flujo del rio es bajo.


```

```{r}
#conclusion del tesista:

#estiaje:

#mayo,junio,julio, agosto, setiembre y octubre   

#transicion(generan cambios inesperados o esperados):

#noviembre, diciembre y enero 

#avenida:

#febrero, marzo y abril.

```

**GRAFICA#ACP con CLUSTER**

GRAFICO 1 
```{r}


#Se puede apreciar que con 2 componentes retenemos 83.8% de la inercia total
library(factoextra)
fviz_cluster(list(data = datosc, cluster = grp),
             palette =c("#DB1515", "#3722BF", "#D41AC4") ,
             ellipse.type = "convex", # Concentration ellipse
             repel = T, # Avoid label overplotting (slow)
             show.clust.cent = FALSE, ggtheme = theme_bw())
```




```{r}
# Juntando el archivo de "datos" con la columna de "cluster"
datos.j <- cbind(datosc,grp)
 
```

```{r}
#convirtiendo en factor la varaible "grp" 
datos.j$grp <- factor(datos.j$grp)

#Si deseamos exportar :
# write.csv(datos.j,"Compras con Jerarquico Aglomerativo.csv")
```

**Analisis de componenentes principales:**


ANALISIS EXPLORATORIO :
```{r}
library(GGally)
ggcorr(datosc)

#Se puede observar  que entre las 24 variables, hay correlaciones muy altas , correlaciones altas  y correlaciones medias.
#esto podria traer problemas de multicolinealidad.
```

Prueba de Esfericidad de Bartlett

```{r}
library(psych)
correlaciones<- corr.test(datosc) # se crea la matriz de correlaciones  
#correlaciones$r                  # existe correlaciones  entre las variables   
library(rela)
r<-as.matrix(correlaciones$r)
options(scipen=999)
cortest.bartlett(r,nrow(datosc))




# Prueba de Esfericidad de Bartlett

#Prueba de Esfericidad de Bartlett
#Ho: |Rp|=1 (las correlaciones teóricas entre cada par de variables es nulo)  
#H1: |Rp|≠1 (las correlaciones teóricas entre cada par de variables NO es nulo)


#conclusion:

#p-valor < 0.05 ,
#se rechaza la H0, se puede afirmar que las las correlaciones teóricas entre cada par de variables NO es nulo.

#en otras palabras nuestra matriz correlacion es diferente a la matriz identidad
#podemos realizar analisis de componentes principales.



```

Indicador Kaiser-Meyer-Olkinn KMO y MSA 

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(psych)
KMO(datosc)     #la advetencia que sale significa que mis varaibles estan altamente correlacionadas

#Por otro lado el indicador "kmo" es superior igual 0.5 que indica que puedo trabajar con todas 
#las 24 variables
```


**3.2Análisis de Componentes Principales con el paquete ade4**

CORROBORANDO LA GRAFICA 1

¿se podra explicar con 2 componentes todas las 24 variables ?

vamos a comprobar:

En el Grafico 1, se podia apreciar que  con 2 componentes(retiene 83.8% de la inercia total) se podria explicar   todas las 24 variables. 

¿Cuantos componentes?
```{r}

library(ade4)

acp <- dudi.pca(datosc,scannf=FALSE,nf=ncol(datosc)) 
summary(acp) 
```
- Podemos observar que con 2 componenetes retenemos 83.79 % de la inercia total

- Podemos observar que con 3 componenetes retenemos 89.49 % de la inercia total

- Podemos observar que con 4 componenetes retenemos 93.32 % de la inercia total

- Podemos observar que con 5 componenetes retenemos 95.73 % de la inercia total





**CRITERIO DE LA MEDIA**

```{r}
# Valores propios

#el criterio de la media:

#estamos trabajando con la matriz correlacion cada variable deberia retener  
#1% de la inercia total , nos quedamos con los 3 primeros autovalores
#que son mayores a 1.
acp$eig 
```
Conclusion:

3 componentes podemos explicar todas las 24 variables reteniendo 89.49 % de la inercia total.

```{r}
# con 3 componetes podemos explicar las todas las 24  variables 
# reteniendo 89.49% de la inercia total
inertia.dudi(acp)
```

¿Como estan agrupadas las variables?

Nos basamos del criterio de las correlaciones 
```{r}
# Correlaciones entre las variables y los componentes



acp$co[c(1,2,3)] 
##############
#componente1:#
##############

#caudal
#temp
#Turb
#CE
#SD
#Akal
#Di
#Cls
#so
#NO3
#NO2
#PO
#Cu
#Al
#Fe
#Mu
#Pb
#Cd
#Zn
#As
#Colo
#Cole

##############
#componente2:#
##############

#OD

##############
#componente3:#
##############

#pH
```

```{r}
# Segunda forma

#podemos observar que todos las variables  estan asociados mas a la  
#dimension 1,excepto "pH" y "OD" que no se sabe con exactitud si pertenece
#a la dimension 1 o a la dimension2 de manera visual, pero con la matriz de
#correlacion ya determinamos la variable "pH" pertenece al componente3 
#y la variable "OD" pertenece al componente2


library(factoextra)
fviz_pca_var(acp, col.var="steelblue")+theme_minimal()
 
```


```{r}

#biplot

library(factoextra)
fviz_pca_biplot(acp, repel = F,
                col.var = "steelblue",
                col.ind = "black" )
###indicadores

```



```{r}
# Grafica de Valores propios - ScreePlot

#El primer componente retiene 74% de la inercia total
#El segundo componete retiene 9.8% de la inercia total
#El tercer componente retiene 5.7% de la inercia total
fviz_eig(acp, addlabels=TRUE, hjust = -0.3,
         barfill="white", barcolor ="darkblue",
         linecolor ="red") + ylim(0,80) + theme_minimal() 
```

```{r}
# Scores o Puntuaciones de cada individuo
acp$li[1:10,]


```

```{r}
# Gráfica de individuos sobre el primer plano de componentes
s.label(acp$li,clabel=0.7,grid=FALSE,boxes=FALSE)
```
